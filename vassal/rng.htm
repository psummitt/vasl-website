<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="">
  <link rel="shortcut icon" href="../favicon.ico">
  <title>VASL - Frequently Asked Questions</title>
  <link rel="stylesheet" href="../css/bootstrap.min.css">
  <link href="../css/vasl_styles.css" rel="stylesheet">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-50258794-1"></script>
  <script>
  window.dataLayer = window.dataLayer || [];

  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'UA-50258794-1');
  </script>
</head>

<body>
  <div id="navbar"></div>
  <div class="container-fluid">
    <div class="row">
      <div class="col-md-2">
        <table width="100%" border="0" cellspacing="10" cellpadding="0">
          <tr>
            <td class="quoteHead" align="center">Questions on VASL?</td>
          </tr>
          <tr>
            <td align="center" class="quoteSource">Send questions to <br><a href="mailto:styson@gmail.com">Sam Tyson</a></td>
          </tr>
        </table>
      </div>
      <div class="main-content col-md-10">
        <h2>How random is VASSAL's dice-roller?</h2>
        <p><a href="mailto:spb@meshuggeneh.net">Stephen P. Berry</a> has done some statistical analysis on a sample of dice rolls
          generated by the VASSAL engine. The short answer is that the results are indistinguishable from a random sample as far as
          any honest player would be able to tell. A maniacally motivated person might be able to guess the generator's seeding
          algorithm and therefore be able to make statistical predictions on future dice rolls based on the history of past dice
          rolls. However, I can recommend some much easier methods of cheating if that's what you're interested in. Here is the
          analysis:</p>
        <p><u>Distribution of rolls</u> From a test set of just over 35,000 2d6 rolls from the dicebot. The distribution looks
          pretty good:
          <p><tt>DR Count Expected</tt><br /><tt></tt><br />
            <p><tt>&nbsp;&nbsp;&nbsp;&nbsp; 2&nbsp; 525&nbsp;&nbsp; 487.4</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp; 3&nbsp; 943&nbsp;&nbsp; 974.9</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp; 4 1484&nbsp; 1462.3</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp; 5 1864&nbsp; 1949.8</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp; 6 2418&nbsp; 2437.2</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp; 7 2934&nbsp; 2924.7</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp; 8 2454&nbsp; 2437.2</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp; 9 1948&nbsp; 1949.8</tt><br />
              <tt>&nbsp;&nbsp;&nbsp; 10 1490&nbsp; 1462.3</tt><br />
              <tt>&nbsp;&nbsp;&nbsp; 11 1005&nbsp;&nbsp; 974.9</tt><br />
              <tt>&nbsp;&nbsp;&nbsp; 12&nbsp; 483&nbsp;&nbsp; 487.4</tt><br />
              <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-------</tt><br />
              <tt>&nbsp; Total&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 17548</tt><br />
              <p>Doing a simple chi-square hypothesis test, we get a chi-square of 9.82, which tells us that we do not reject the null
                hypothesis that <b>the data conforms to the random distribution at a significance level of 0.001</b>. The numbers work out
                even better if you just look at 1d6 instead of 2d6. So ...this tells us that the PRNG is spitting out numbers that are
                pretty uniform on {1, 2, 3, 4, 5, 6}.
                <p><u>Correlation between rolls</u> To test correlation between rolls, a count is kept for each pair {d[n - 1], d[n]} for
                  n from 2 to the number of total dr.&nbsp; The average is figured as ((1/6)^2) * (n - 1), and a chi-square computed.&nbsp;
                  The results for the 85450 1d6 I have data on are fine:
                  <p>&nbsp;<tt> d[n] d[n-1] Count</tt><br /><tt></tt><br />
                    <p><tt>&nbsp; 1 1 2402</tt><br />
                      <tt>&nbsp; 1 2 2334</tt><br />
                      <tt>&nbsp; 1 3 2387</tt><br />
                      <tt>&nbsp; 1 4 2306</tt><br />
                      <tt>&nbsp; 1 5 2361</tt><br />
                      <tt>&nbsp; 1 6 2428</tt><br />
                      <tt>&nbsp; 2 1 2378</tt><br />
                      <tt>&nbsp; 2 2 2334</tt><br />
                      <tt>&nbsp; 2 3 2427</tt><br />
                      <tt>&nbsp; 2 4 2343</tt><br />
                      <tt>&nbsp; 2 5 2381</tt><br />
                      <tt>&nbsp; 2 6 2352</tt><br />
                      <tt>&nbsp; 3 1 2432</tt><br />
                      <tt>&nbsp; 3 2 2325</tt><br />
                      <tt>&nbsp; 3 3 2329</tt><br />
                      <tt>&nbsp; 3 4 2347</tt><br />
                      <tt>&nbsp; 3 5 2404</tt><br />
                      <tt>&nbsp; 3 6 2429</tt><br />
                      <tt>&nbsp; 4 1 2309</tt><br />
                      <tt>&nbsp; 4 2 2390</tt><br />
                      <tt>&nbsp; 4 3 2337</tt><br />
                      <tt>&nbsp; 4 4 2295</tt><br />
                      <tt>&nbsp; 4 5 2350</tt><br />
                      <tt>&nbsp; 4 6 2301</tt><br />
                      <tt>&nbsp; 5 1 2347</tt><br />
                      <tt>&nbsp; 5 2 2475</tt><br />
                      <tt>&nbsp; 5 3 2390</tt><br />
                      <tt>&nbsp; 5 4 2302</tt><br />
                      <tt>&nbsp; 5 5 2547</tt><br />
                      <tt>&nbsp; 5 6 2424</tt><br />
                      <tt>&nbsp; 6 1 2351</tt><br />
                      <tt>&nbsp; 6 2 2357</tt><br />
                      <tt>&nbsp; 6 3 2396</tt><br />
                      <tt>&nbsp; 6 4 2388</tt><br />
                      <tt>&nbsp; 6 5 2442</tt><br />
                      <tt>&nbsp; 6 6 2349</tt><br />
                      <p><tt>Expected value for each count:&nbsp; 2373.58333333333</tt><br />
                        <tt>Chi-square:&nbsp; 43.0407260471158</tt><br />
                        <tt>For df=35:&nbsp; p=0.01 p=0.005 p=0.001</tt><br />
                        <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;49.80 57.34 66.62</tt><br />
                        <p>...so <b>there's no evidence there that the distribution of pairs of successive dr are not independent.</b><b></b>
                          <p>Another test of correlations is popularly called the coupon collector's test. For the current audience, instead of
                            coupons we might think of baseball cards or any other widget that comes in sets of which you want to 'collect all n', for
                            some sufficiently marketable value of n.
                            <p>The idea is that we walk through our data, starting with an empty set, then add the elements of our data to the set,
                              one by one, until we have acomplete set of one of each type (not counting duplicates). So for my dataset of 85450 1d6, we
                              start with a set of zero 1s, zero 2s, and so on. Each time we see a new dr, we add it to our set. We keep track of how
                              long it takes us to get a complete set of the numbers in [1, 6], then re-start from an empty set (selling the completed
                              set on eBay, complete with photocopies of a couple other dr) and do it again.</p>
                            <p>After counting up the length between complete sets (i.e., the number of dr we had look through before we got one of
                              each possible dr) we can do a trust ol' chi-square on the resulting data, where the probability for each length will
                              be:</p>
                            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d!&nbsp;
                              <tt>p(r) = ----- * S((r - 1), (d - 1)) , d &lt;= r &lt; t</tt><br />
                              <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; d^r</tt><br /><tt></tt><br />
                              <p><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d!</tt><br />
                                <tt>&nbsp;p(t) = 1 - ----------- * S((t - 1), d)</tt><br />
                                <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d^(t - 1)</tt><br />
                                <p>...where: r is the length in question; d is the number of items in a complete set; S(n,m) is the Stirling number of the
                                  second kind (which is the number of ways you can partition a set of n elements into m disjoint, nonempty subsets; and t
                                  the upper bound of the lengths we're going to consider (so if we were interested in lengths from 1 to 10, t would be 11.
                                  we'll choose t such that the expected value for the highest r will be around 1. If this doesn't make sense, just peek down
                                  at the data and it'll probably be more clear).</p>
                                <p>We multiply these values for p(r) with the total number of lengths we measure to obtain an expected value for each
                                  length, then do our chi-square.</p>
                                <p>The data once again looks good:
                                  <p><tt>Length Count Expected Value</tt><br /><tt></tt><br />
                                    <p><tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6&nbsp; 85&nbsp;&nbsp; 89.75309</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 7 223&nbsp; 224.38272</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8 372&nbsp; 349.03978</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9 420&nbsp; 436.29973</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 10 475&nbsp; 481.38403</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 11 477&nbsp; 490.83719</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 12 490&nbsp; 474.63947</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 13 477&nbsp; 442.26326</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 14 401&nbsp; 401.22929</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 15 377&nbsp; 356.91274</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 16 293&nbsp; 312.85229</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 17 247&nbsp; 271.18876</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 18 235&nbsp; 233.07425</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 19 185&nbsp; 199.00003</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 20 174&nbsp; 169.03892</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 21 162&nbsp; 143.01511</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 22 104&nbsp; 120.61831</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 23&nbsp; 99&nbsp; 101.47771</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 24&nbsp; 75&nbsp;&nbsp; 85.20793</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 25&nbsp; 68&nbsp;&nbsp; 71.43616</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 26&nbsp; 50&nbsp;&nbsp; 59.81688</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 27&nbsp; 57&nbsp;&nbsp; 50.03876</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 28&nbsp; 54&nbsp;&nbsp; 41.82664</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 29&nbsp; 24&nbsp;&nbsp; 34.94069</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 30&nbsp; 39&nbsp;&nbsp; 29.17404</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 31&nbsp; 23&nbsp;&nbsp; 24.34958</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 32&nbsp; 24&nbsp;&nbsp; 20.31657</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 33&nbsp; 21&nbsp;&nbsp; 16.94732</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 34&nbsp; 13&nbsp;&nbsp; 14.13400</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 35&nbsp; 11&nbsp;&nbsp; 11.78582</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 36&nbsp; 10&nbsp;&nbsp;&nbsp; 9.82651</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 37&nbsp; 11&nbsp;&nbsp;&nbsp; 8.19208</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 38&nbsp;&nbsp; 7&nbsp;&nbsp;&nbsp; 6.82895</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 39&nbsp;&nbsp; 9&nbsp;&nbsp;&nbsp; 5.69227</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 40&nbsp;&nbsp; 5&nbsp;&nbsp;&nbsp; 4.74455</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 41&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp; 3.95445</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 42&nbsp;&nbsp; 5&nbsp;&nbsp;&nbsp; 3.29581</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 43&nbsp;&nbsp; 3&nbsp;&nbsp;&nbsp; 2.74680</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 44&nbsp;&nbsp; 2&nbsp;&nbsp;&nbsp; 2.28920</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 45&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp; 1.90779</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 46&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp; 1.58991</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 47&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp; 1.32499</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 48&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp; 1.10419</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp; 49&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp; 0.92019</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp; =50&nbsp;&nbsp; 5&nbsp;&nbsp;&nbsp; 4.60124</tt><br />
                                      <tt>&nbsp;</tt><br />
                                      <tt>Chi-square:&nbsp;&nbsp;&nbsp; 41.73981</tt><br />
                                      <tt>For df=43:&nbsp; p=0.01 p=0.005 p=0.001</tt><br />
                                      <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;59.30 67.46 77.42</tt><br />
                                      <p>So...once again we aren't forced to reject the null hypothesis; <b>there's no evidence that the dice are biased in a
                                          statistically significant way.</b></p>
                                      <p>There's a more general test for this sort of thing, called a 'birthday spacings' test (e.g., in Marsaglia's
                                        DIEHARD).</p>
                                      <p>Imagine you have an arbitrary calendar of d days. Select b birthdays out of that calendar, and list them in
                                        nondescending order. Make a list of the distances between the birthdays, then sort them into nondescending order. Go
                                        through the list of distances, and count the number of times a distance is the same as the one that preceeded it (i.e.,
                                        for distances s[0, 1, ...], count the times s[i] = s[i - 1]). Call this number n. Assuming that the birthdays were
                                        selected at random, then n should be Poisson distributed with a lambda of (b^3)/(4d). According to Marsaglia,
                                        experimentation suggests that you need d >= 2^18.</p>
                                      <p>What are we doing here? We're just trying to come up with a general model that lets us figure out what an expected
                                        distribution for the differences between dr is. The birthday spacings test gives us such a model. Now we need to find a
                                        way to convert our dr into birthdays in a calendar (with lots and lots of days...specifically, at least 2^18 days).</p>
                                      <p>Okay. If we tried just mapping our die rolls directly to birthdays, we'd end up with a calendar with at most 6 days.
                                        That's somewhat less than our desired 2^18. So we figure ln(2^18)/ln(6) = 6.96. This tells us that 2^18 is roughly 6^6.96.
                                        What does this mean? Well, we're trying to figure out how many dr we need to string together to make a problem space
                                        roughly the same size as our desired calendar. Put in somewhat different terms, we can imagine a binary number as a bunch
                                        of coin tosses (each coin has two states---heads or tails---just like each bit has two states---0 or 1). What we're
                                        figuring out is more or less how many die rolls (things with six states) have as many possible combinations as 18 coin
                                        tosses (things with two states).</p>
                                      <p>So if we do 18 coin tosses, there are 2^18 or 262144 possible results. By doing the ln(2^18)/ln(6) = 6.96, we're
                                        discovering that in order to get this many possible results out of die rolls, we need to roll about 6.96 dice. Call it 7
                                        dr, for a total of 6^7 = 279936 possible results---just over what we need.</p>
                                      <p>This also tells us that when we're looking at the dice to generate birthdays in our calendar with 279936 days, we'll
                                        need to roll 7 dice at a time. We'll also have to subtract one from each dr to insure we can generate numbers from 0 to
                                        279935. So if we look at seven dr {1, 1, 1, 1, 1, 1, 2} we'd read that as (6^6 * 0) + (6^5 * 0) + (6^4 * 0) + (6^3 * 0) +
                                        (6^2 * 0) + (6^1 * 0) + (6^0 * 1) = 1. And the dr {6, 6, 6, 6, 6, 6, 6} would be (6^6 * 5) + (6^5 * 5) + (6^4 * 5) + (6^3
                                        * 5) + (6^2 * 5) + (6^1 * 5) + (6^0 * 5) = 279935.</p>
                                      <p>Okay. This all defined, we can grab dr, seven at a time, and convert them into an integer in [0, 279935]. We can then
                                        walk through our data starting from the first dr and compute the number of recurrent birthday distances (our value n above
                                        in the original description of the test). We'll choose a number of birthdays per test that will keep our lambda managable.
                                        With 130 birthdays per test, it works out to (130^3) / (4 * 6^7) or about 1.96 . We plug this into the Poisson equation:</p>
                                      <p><tt>&nbsp;&nbsp; (e^(-l))(l^x)</tt><br />
                                        <tt>&nbsp; P(x) = ---------------</tt><br />
                                        <tt>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;x!</tt><br />
                                        <p>...where: l is our lambda and x is the number of collisions we're interested in {0, 1, 2, 3...}. We'll actually decide
                                          on a maximum value for x based on the data (the number of collisions will always be fairly small, and the expected number
                                          will depend on the number of samples we take). We'll also use the expected number and the observed number to do a
                                          chi-square test to get a p value for the test.</p>
                                        <p>So much for the theory. Propping the poncho lifter back on my F2 key, I generated another 50354 dr which, along with my
                                          original data total up to 85450 dr.</p>
                                        <p>I knocked together some code to run through multiple tests on these data, grabbing 910 dr at a go. That's 130 birthdays
                                          per test (as determined above), and 7 dr per birthday. So we'll get a total of (85450 / 910) = 93.9 collision counts.
                                          Ignoring the partial data set, we'll go with 93 values for n.</p>
                                        <p>Reading through the data, before doing anything else, a chi-square value for the birthdays is determined---just to
                                          insure that our data aren't 'failing' before we go further. Then the rest of the mechanics of the birthday spacings test
                                          are run through.</p>
                                        <p>So much for the code. After a little number crunching, we learn:</p>
                                        <p>&nbsp;<tt>Duplicate&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Observed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Expected</tt><br />
                                          <tt>&nbsp;Spacings&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Number&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Number</tt><br />
                                          <tt>&nbsp;--------&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ------&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;------</tt><br />
                                          <tt>&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;12&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 13.073</tt><br />
                                          <tt>&nbsp;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;34&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 25.650</tt><br />
                                          <tt>&nbsp;2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;16&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 25.163</tt><br />
                                          <tt>&nbsp;3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;19&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16.457</tt><br />
                                          <tt>&nbsp;4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;10&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.072</tt><br />
                                          <tt>&nbsp;5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.168</tt><br />
                                          <tt>&nbsp;6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.036</tt><br />
                                          <tt>&nbsp;7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.290</tt><br />
                                          <tt>&nbsp;8&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.071</tt><br />
                                          <tt>&nbsp;9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.016</tt><br /><tt></tt><br />
                                          <p><tt>Chi-square: 8.83976326165167</tt></p>
                                          <p>This is pretty darn good. We're certainly not lead to reject H0 at any meaningful significance level. It's also worth
                                            noting that the birthday spacings test is often failed by PRNGs[3], so this is heartening for the suitability of the
                                            underlying PRNG for use in the dicebot.</p>
                                          <p>So this is a pretty strong indicator that <b>we don't have statistically significant correlations between arbitrary
                                              numbers output by the dice bot</b>.</p>
      </div>
    </div>
  </div>
  <footer></footer>
  <script src="../js/jquery.min.js"></script>
  <script src="../js/bootstrap.min.js"></script>
  <script type="text/javascript">
  $(document).ready(function() {
    $("#navbar").load("../include/navbar.htm", function() {
      $("ul.navbar-nav li.faq").addClass("active");
    });
    $("footer").load("../include/copyright.htm");
  });
  </script>
</body>

</html>